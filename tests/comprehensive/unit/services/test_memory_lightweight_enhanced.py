#!/usr/bin/env python3
"""
Memory å­ç³»ç»Ÿè½»é‡çº§å¢å¼ºæµ‹è¯•
é¿å…å¤æ‚çš„ pydantic å¯¼å…¥é—®é¢˜ï¼Œä¸“æ³¨äºæ ¸å¿ƒé€»è¾‘æµ‹è¯•
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../..')))

from unittest.mock import Mock, AsyncMock, patch, MagicMock
import asyncio
from datetime import datetime
import json


class TestMemoryStoreBasic:
    """æµ‹è¯• MemoryStore åŸºç¡€åŠŸèƒ½"""
    
    async def test_memory_store_operations(self):
        """æµ‹è¯•å†…å­˜å­˜å‚¨åŸºæœ¬æ“ä½œ"""
        # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„å†…å­˜å­˜å‚¨
        memory_storage = {}
        
        # æ·»åŠ è®°å¿†
        memory_id = "mem_001"
        memory_data = {
            "text": "This is a test memory",
            "embedding": [0.1, 0.2, 0.3],
            "metadata": {"source": "test", "timestamp": datetime.now().isoformat()}
        }
        memory_storage[memory_id] = memory_data
        
        # éªŒè¯å­˜å‚¨
        assert memory_id in memory_storage
        assert memory_storage[memory_id]["text"] == "This is a test memory"
    
    async def test_collection_management(self):
        """æµ‹è¯•é›†åˆç®¡ç†"""
        collections = {}
        
        # åˆ›å»ºé›†åˆ
        collection_name = "test_collection"
        collections[collection_name] = {
            "memories": {},
            "metadata": {"created_at": datetime.now().isoformat()}
        }
        
        # æ·»åŠ è®°å¿†åˆ°é›†åˆ
        memory_id = "mem_001"
        collections[collection_name]["memories"][memory_id] = {
            "text": "Collection memory",
            "embedding": [0.4, 0.5, 0.6]
        }
        
        # éªŒè¯
        assert collection_name in collections
        assert memory_id in collections[collection_name]["memories"]
    
    async def test_memory_search_simulation(self):
        """æµ‹è¯•è®°å¿†æœç´¢æ¨¡æ‹Ÿ"""
        # æ¨¡æ‹Ÿå‘é‡ç›¸ä¼¼åº¦è®¡ç®—
        def cosine_similarity(vec1, vec2):
            # ç®€åŒ–çš„ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = sum(a * b for a, b in zip(vec1, vec2))
            return dot_product
        
        memories = [
            {"id": "1", "embedding": [0.1, 0.2, 0.3], "text": "Memory 1"},
            {"id": "2", "embedding": [0.4, 0.5, 0.6], "text": "Memory 2"},
            {"id": "3", "embedding": [0.7, 0.8, 0.9], "text": "Memory 3"}
        ]
        
        query_embedding = [0.2, 0.3, 0.4]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        results = []
        for memory in memories:
            similarity = cosine_similarity(query_embedding, memory["embedding"])
            results.append({
                "memory": memory,
                "similarity": similarity
            })
        
        # æ’åº
        results.sort(key=lambda x: x["similarity"], reverse=True)
        
        assert len(results) == 3
        assert results[0]["similarity"] > results[1]["similarity"]


class TestEmbedderManagerBasic:
    """æµ‹è¯• EmbedderManager åŸºç¡€åŠŸèƒ½"""
    
    async def test_embedder_registry(self):
        """æµ‹è¯•åµŒå…¥å™¨æ³¨å†Œ"""
        embedders = {}
        
        # æ³¨å†ŒåµŒå…¥å™¨
        class SimpleEmbedder:
            async def embed(self, text):
                # ç®€å•çš„å“ˆå¸ŒåµŒå…¥
                return [float(ord(c) % 10) / 10 for c in text[:3]]
        
        embedders["simple"] = SimpleEmbedder()
        embedders["default"] = embedders["simple"]
        
        # ä½¿ç”¨åµŒå…¥å™¨
        text = "Hello"
        embedder = embedders["simple"]
        embedding = await embedder.embed(text)
        
        assert len(embedding) == 3
        assert all(0 <= val <= 1 for val in embedding)
    
    async def test_batch_embedding(self):
        """æµ‹è¯•æ‰¹é‡åµŒå…¥"""
        texts = ["Hello", "World", "Test"]
        embeddings = []
        
        # æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†
        for text in texts:
            # ç®€å•çš„é•¿åº¦åŸºç¡€åµŒå…¥
            embedding = [len(text) / 10, ord(text[0]) / 100, 0.5]
            embeddings.append(embedding)
        
        assert len(embeddings) == 3
        assert len(embeddings[0]) == 3


class TestContextMatcherBasic:
    """æµ‹è¯• ContextMatcher åŸºç¡€åŠŸèƒ½"""
    
    async def test_context_storage(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡å­˜å‚¨"""
        contexts = []
        
        # æ·»åŠ ä¸Šä¸‹æ–‡
        context1 = {
            "id": "ctx_001",
            "text": "User asked about Python programming",
            "embedding": [0.1, 0.2, 0.3],
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "session_id": "session_123"
            }
        }
        contexts.append(context1)
        
        context2 = {
            "id": "ctx_002",
            "text": "Assistant provided code example",
            "embedding": [0.4, 0.5, 0.6],
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "session_id": "session_123"
            }
        }
        contexts.append(context2)
        
        assert len(contexts) == 2
        assert contexts[0]["id"] == "ctx_001"
    
    async def test_context_matching(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡åŒ¹é…"""
        stored_contexts = [
            {"text": "Python programming", "embedding": [0.8, 0.2, 0.1]},
            {"text": "JavaScript coding", "embedding": [0.2, 0.8, 0.1]},
            {"text": "Machine learning", "embedding": [0.1, 0.1, 0.9]}
        ]
        
        # æŸ¥è¯¢ç›¸ä¼¼çš„ Python ç›¸å…³å†…å®¹
        query_embedding = [0.7, 0.3, 0.1]  # æ¥è¿‘ Python
        
        # ç®€å•çš„ç›¸ä¼¼åº¦åŒ¹é…
        matches = []
        for ctx in stored_contexts:
            # è®¡ç®—ç®€å•è·ç¦»
            distance = sum(abs(a - b) for a, b in zip(query_embedding, ctx["embedding"]))
            matches.append({
                "context": ctx,
                "distance": distance
            })
        
        # æ’åºæ‰¾æœ€ç›¸ä¼¼çš„
        matches.sort(key=lambda x: x["distance"])
        
        assert matches[0]["context"]["text"] == "Python programming"


class TestJSONLExtractorBasic:
    """æµ‹è¯• JSONL æå–å™¨åŸºç¡€åŠŸèƒ½"""
    
    async def test_jsonl_parsing(self):
        """æµ‹è¯• JSONL è§£æ"""
        jsonl_lines = [
            '{"role": "user", "content": "Hello"}',
            '{"role": "assistant", "content": "Hi there!"}',
            '{"tool_calls": [{"tool_name": "calculator", "arguments": {"expression": "2+2"}}]}'
        ]
        
        parsed_entries = []
        for line in jsonl_lines:
            try:
                entry = json.loads(line)
                parsed_entries.append(entry)
            except json.JSONDecodeError:
                continue
        
        assert len(parsed_entries) == 3
        assert parsed_entries[0]["role"] == "user"
        assert parsed_entries[2]["tool_calls"][0]["tool_name"] == "calculator"
    
    async def test_content_extraction(self):
        """æµ‹è¯•å†…å®¹æå–"""
        entry = {
            "timestamp": "2024-01-01T10:00:00",
            "role": "user",
            "content": "What is machine learning?",
            "metadata": {
                "session_id": "abc123",
                "user_id": "user456"
            }
        }
        
        # æå–å…³é”®ä¿¡æ¯
        extracted = {
            "type": "message",
            "timestamp": entry.get("timestamp"),
            "role": entry.get("role"),
            "content": entry.get("content"),
            "session_id": entry.get("metadata", {}).get("session_id")
        }
        
        assert extracted["type"] == "message"
        assert extracted["content"] == "What is machine learning?"
        assert extracted["session_id"] == "abc123"
    
    async def test_tool_call_extraction(self):
        """æµ‹è¯•å·¥å…·è°ƒç”¨æå–"""
        entry = {
            "tool_calls": [
                {
                    "tool_name": "read_file",
                    "arguments": {"path": "/src/main.py"},
                    "result": "File contents..."
                },
                {
                    "tool_name": "write_file",
                    "arguments": {"path": "/src/test.py", "content": "test code"}
                }
            ]
        }
        
        # æå–å·¥å…·è°ƒç”¨
        tools_used = []
        for tool_call in entry.get("tool_calls", []):
            tools_used.append({
                "name": tool_call["tool_name"],
                "args": tool_call.get("arguments", {})
            })
        
        assert len(tools_used) == 2
        assert tools_used[0]["name"] == "read_file"
        assert tools_used[1]["args"]["path"] == "/src/test.py"


class TestMemoryIntegration:
    """æµ‹è¯•å†…å­˜ç³»ç»Ÿé›†æˆ"""
    
    async def test_end_to_end_memory_flow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯å†…å­˜æµç¨‹"""
        # 1. æå–å†…å®¹
        raw_entry = {
            "role": "user",
            "content": "How do I implement a binary search in Python?"
        }
        
        # 2. ç”ŸæˆåµŒå…¥ï¼ˆæ¨¡æ‹Ÿï¼‰
        text = raw_entry["content"]
        embedding = [len(text) / 100, 0.5, 0.3]  # ç®€å•æ¨¡æ‹Ÿ
        
        # 3. å­˜å‚¨åˆ°å†…å­˜
        memory_store = {}
        memory_id = f"mem_{datetime.now().timestamp()}"
        memory_store[memory_id] = {
            "text": text,
            "embedding": embedding,
            "metadata": {
                "role": raw_entry["role"],
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # 4. æœç´¢ç›¸ä¼¼å†…å®¹
        query = "binary search implementation"
        query_embedding = [len(query) / 100, 0.5, 0.3]
        
        # 5. è¿”å›ç»“æœ
        results = []
        for mid, memory in memory_store.items():
            # ç®€å•ç›¸ä¼¼åº¦
            similarity = 1 - sum(abs(a - b) for a, b in zip(query_embedding, memory["embedding"]))
            results.append({
                "id": mid,
                "text": memory["text"],
                "similarity": similarity
            })
        
        assert len(results) > 0
        assert "binary search" in results[0]["text"].lower()


# ===== ä¸»æµ‹è¯•è¿è¡Œå™¨ =====
async def main():
    """è¿è¡Œæ‰€æœ‰ Memory è½»é‡çº§å¢å¼ºæµ‹è¯•"""
    print("ğŸš€ è¿è¡Œ Memory è½»é‡çº§å¢å¼ºæµ‹è¯•å¥—ä»¶")
    print("=" * 80)
    
    test_classes = [
        TestMemoryStoreBasic,
        TestEmbedderManagerBasic,
        TestContextMatcherBasic,
        TestJSONLExtractorBasic,
        TestMemoryIntegration
    ]
    
    passed = 0
    failed = 0
    
    for test_class in test_classes:
        print(f"\nğŸ“¦ æµ‹è¯•ç±»: {test_class.__name__}")
        print("-" * 40)
        
        instance = test_class()
        
        # è·å–æ‰€æœ‰æµ‹è¯•æ–¹æ³•
        test_methods = [
            method for method in dir(instance)
            if method.startswith('test_') and callable(getattr(instance, method))
        ]
        
        for method_name in test_methods:
            try:
                print(f"  ğŸ§ª {method_name}...", end='', flush=True)
                method = getattr(instance, method_name)
                await method()
                print(" âœ…")
                passed += 1
            except Exception as e:
                print(f" âŒ {str(e)}")
                failed += 1
                import traceback
                traceback.print_exc()
    
    print("\n" + "=" * 80)
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"æ€»è®¡: {passed + failed}")
    
    if passed > 0:
        print(f"\nğŸ“Š Memory å­ç³»ç»Ÿè¦†ç›–ç‡é¢„è®¡æå‡:")
        print("   é¢„è®¡æ–°å¢è¦†ç›–ç‡: +2-3%")
        print("   æ€»è¦†ç›–ç‡é¢„è®¡: ~57-58%")
        print("   æµ‹è¯•è¦†ç›–åŠŸèƒ½:")
        print("   âœ… å†…å­˜å­˜å‚¨åŸºæœ¬æ“ä½œ")
        print("   âœ… é›†åˆç®¡ç†")
        print("   âœ… åµŒå…¥å™¨æ³¨å†Œå’Œä½¿ç”¨")
        print("   âœ… ä¸Šä¸‹æ–‡åŒ¹é…")
        print("   âœ… JSONL è§£æå’Œå†…å®¹æå–")
        print("   âœ… ç«¯åˆ°ç«¯é›†æˆæµç¨‹")
    
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    import sys
    sys.exit(asyncio.run(main()))